# KANs {.unnumbered}

## Materials:
Date: Saturday, 21-Sep-2024, 1.30pm, IST.

### Pre-work:

- Refresh ML foundations.
- Read "The 100 page ML book" by Andiry Burkov. Chapters accessible [here](https://themlbook.com/wiki/doku.php)
- [FFNs](./L01.qmd) 
- [CNNs](./L02.qmd) 



### In-Class

- [KAN: Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756)
- Implementation [PyKAN](https://github.com/KindXiaoming/pykan)
- Implementation [Efficient-KAN](https://github.com/Blealtan/efficient-kan)
- [KAN 2.0: Kolmogorov-Arnold Networks Meet Science](https://arxiv.org/abs/2408.10205)

    
### Lab

- [Fit a function](./../notebooks/02-01-KAN-Intro.ipynb) from [PyKAN](https://github.com/KindXiaoming/pykan) simple functions (tbd)
- [Splines](./../notebooks/02-02-KAN-Splines.ipynb) from [PyKAN](https://github.com/KindXiaoming/pykan on a Doppler function. 
- [RBFs](./../notebooks/02-03-KAN-RBFs.ipynb) from [Fast-KAN](https://github.com/ZiyaoLi/fast-kan) on a Doppler function
- [Chebyshev Polynomials](./../notebooks/02-04-KAN-Chebyshev.ipynb) from [ChebyKAN](https://github.com/SynodicMonth/ChebyKAN) on a Doppler function
- [Wavelets](./../notebooks/02-05-KAN-Wavelets.ipynb) from [WavKAN](https://github.com/zavareh1/Wav-KAN) on a Doppler function
- [PDE solver](./../notebooks/02-07-KAN-PDE.ipynb)
- [Wavelets with IWT](./../notebooks/02-06-KAN-PyWavelets.ipynb)
- [Wavelet Regression in Python](https://github.com/jseabold/web-site/blob/master/content/notebooks/wavelet-regression-in-python.ipynb)

### Post-class:

- \[paper\] [Chebyshev KAN](https://arxiv.org/abs/2405.07200v1) Chebyshev Polynomial-Based Kolmogorov-Arnold Networks: An Efficient Architecture for Nonlinear Function Approximation. Implementation [ChebyKAN](https://github.com/SynodicMonth/ChebyKAN) 
- \[paper\] [Survey of KANs](https://arxiv.org/abs/2407.11075) A Comprehensive Survey on Kolmogorov Arnold Networks (KAN)
- \[code\] [Fast KAN](https://github.com/ZiyaoLi/fast-kan) Replace B-splines with RBF to make it 3.3x faster than [Efficient-KAN](https://github.com/Blealtan/efficient-kan) 
- \[paper\][Kolmogorov-Arnold Convolutions: Design Principles and Empirical Studies](https://arxiv.org/abs/2407.01092) | [code](https://github.com/IvanDrokin/torch-conv-kan)
- \[collection\] [awesome KANs](https://github.com/mintisan/awesome-kan) - a collection of papers, codes, tutorials on KANs.



### KAN Papers and Advancements

- [KAN vs MLP ](https://arxiv.org/abs/2407.16674) KAN or MLP: A Fairer Comparison
- [KANs for PINNs](https://arxiv.org/abs/2406.11045) Kolmogorov Arnold Informed neural network: A physics-informed deep learning framework for solving forward and inverse problems based on Kolmogorov Arnold Networks
- [Wav-KAN](https://arxiv.org/abs/2405.12832) Wav-KAN: Wavelet Kolmogorov-Arnold Networks
- [KAN GPT](https://github.com/AdityaNG/kan-gpt)

### Theory

- 1957-[On the representation of continuous functions of several variables by superpositions of continuous functions of a smaller number of variables](https://cs.uwaterloo.ca/~y328yu/classics/Kolmogorov57.pdf) : The original Kolmogorov Arnold paper
- 1957-[On functions of three variables](https://cs.uwaterloo.ca/~y328yu/classics/Arnold57.pdf)
- 2009-[On a constructive proof of Kolmogorovâ€™s superposition theorem](https://ins.uni-bonn.de/media/public/publication-media/remonkoe.pdf?pk=82)
- 2021-[The Kolmogorov-Arnold representation theorem revisited](https://arxiv.org/abs/2007.15884)
- 2021-[The Kolmogorov Superposition Theorem can Break the Curse of Dimension When Approximating High Dimensional Functions](https://arxiv.org/pdf/2112.09963)

### References

- R01: [CS6910: Deep Learning](http://www.cse.iitm.ac.in/~miteshk/CS6910.html) Mitesh Khapra @ IIT Madras
- R02:  [CS7015: Deep Learning](https://www.cse.iitm.ac.in/~miteshk/CS7015_2019.html) Mitesh Khapra @ IIT Madras(earlier version of CS6910)
- R03: [LING 574: Deep Learning for NLP](https://www.shane.st/teaching/574/spr24/) Shane Steinhard-Threlkeld @ University of Washington
- R04: [Dive into Deep Learning](https://d2l.ai/index.html)
- R05: [Understanding Deep Learning](https://udlbook.github.io/udlbook/)
- R06: [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)
- R07: [Deep Learning for Computer Vision](https://archive.nptel.ac.in/noc/courses/noc20/SEM2/noc20-cs88/) NPTEL course by Prof. Vineeth N Balasubramanian

### Additional References

- \[Book\] [Essential Wavelets for Statistical Applications and Data Analysis](- \[Book\] [All of Nonparametric Statistics](https://www.amazon.com/gp/product/1441920447/ref=as_li_qf_sp_asin_tl?ie=UTF8&tag=scistapro-20&linkCode=as2&
- \[Book\] [All of Nonparametric Statistics](https://www.stat.cmu.edu/~larry/all-of-nonpar/index.html) - Chapter 9
- \[Book\] [Functional Data Analysis](https://link.springer.com/book/10.1007/b98888) Chapter 3 on Fourier basis, Splines, Wavelets and Polynomials
- \[Book\] [Functional Data Analysis with R and MATLAB](https://link.springer.com/book/10.1007/978-0-387-98185-7) - Chapter 2 on specifying basis functions 
- \[Book\] [Generalized Additive Models](https://www.taylorfrancis.com/books/mono/10.1201/9780203753781/generalized-additive-models-hastie) by Hastie and Tibshirani. [paper](https://projecteuclid.org/journals/statistical-science/volume-1/issue-3/Generalized-Additive-Models/10.1214/ss/1177013604.full)
- \[Tutorial\] [Functional Regression](https://arxiv.org/abs/1406.4068)
- \[Tutorial\] [Functional Data Analysis: An Introduction and Recent Developments](https://arxiv.org/abs/2312.05523)
